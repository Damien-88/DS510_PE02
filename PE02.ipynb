{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSUSowAaCFAF"
      },
      "source": [
        "# HOS02"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nwH-p03YqqU1"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myEHcWNQq8kT",
        "outputId": "1229d840-6c2a-4596-8c89-b7158b97f724"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.Vector to be normalized [0.0002, 0.2, 0.9, 0.0001, 0.4, 0.6]\n"
          ]
        }
      ],
      "source": [
        "# y is the vector of the scores of the lv vector in the warehouse example.\n",
        "y = [0.0002, 0.2, 0.9, 0.0001, 0.4, 0.6]\n",
        "print(\"0.Vector to be normalized\", y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ff3WD3rArU8p",
        "outputId": "f53e8912-7dcb-4a1c-ae08-14b7e13b077f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 [1.0002000200013335, 1.2214027581601699, 2.45960311115695, 1.0001000050001667, 1.4918246976412703, 1.8221188003905089]\n",
            "2 [1.0, 1.22, 2.46, 1.0, 1.49, 1.82]\n",
            "3 9.0\n",
            "4 [1, 1, 2, 1, 1, 2]\n",
            "5 [0.111, 0.136, 0.273, 0.111, 0.166, 0.203]\n"
          ]
        }
      ],
      "source": [
        "# Version 1: Explicitly writing the softmax function for this case\n",
        "y_exp = [math.exp(i) for i in y]\n",
        "print(\"1\", [i for i in y_exp])\n",
        "print(\"2\", [round(i, 2) for i in y_exp])\n",
        "\n",
        "sum_exp_yi = sum(y_exp)\n",
        "print(\"3\", round(sum_exp_yi, 2))\n",
        "print(\"4\", [round(i) for i in y_exp])\n",
        "\n",
        "softmax = [round(i / sum_exp_yi, 3) for i in y_exp]\n",
        "print(\"5\", softmax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9B18WBurso-Y",
        "outputId": "f68fd41b-332e-4a1d-86e4-de884352c20f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6: Normalized vector [0.111, 0.136, 0.273, 0.111, 0.166, 0.203]\n"
          ]
        }
      ],
      "source": [
        "# Version 2: Explicitly but with no comments\n",
        "y_exp = [math.exp(i) for i in y]\n",
        "sum_exp_yi = sum(y_exp)\n",
        "softmax = [round(i / sum_exp_yi, 3) for i in y_exp]\n",
        "print(\"6: Normalized vector\", softmax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTi8TMV-tZNQ",
        "outputId": "4a66b555-6304-4683-c917-08785c16fd99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7A: Normalized vector [0.11119203 0.13578309 0.27343357 0.11118091 0.16584584 0.20256457]\n",
            "7B: Sum of the normalized vector 1.0\n",
            "7C: Finding the highest value in the normalized vector 0.273433565193713\n",
            "7D: For One-Hot function, the highest value will be rounded to 1 then set all other values of the vector to 0\n",
            "This is a vector that is an output of a one-hot function on a softmax vector\n",
            "[0. 0. 1. 0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "# Version 3L Using a function in a 2 line code instead of 3 lines\n",
        "def softmax(x):\n",
        "  return np.exp(x) / np.sum(np.exp(x), axis = 0)\n",
        "\n",
        "print(\"7A: Normalized vector\", softmax(y))\n",
        "print(\"7B: Sum of the normalized vector\", sum(softmax(y)))\n",
        "\n",
        "ohot = max(softmax(y))\n",
        "ohotv = softmax(y)\n",
        "\n",
        "print(\"7C: Finding the highest value in the normalized vector\", ohot)\n",
        "print(\"7D: For One-Hot function, the highest value will be rounded to 1 then set all other values of the vector to 0\")\n",
        "\n",
        "for onehot in range(6):\n",
        "  if ohotv[onehot] < ohot:\n",
        "    ohotv[onehot] = 0\n",
        "  if ohotv[onehot] >= ohot:\n",
        "    ohotv[onehot] = 1\n",
        "\n",
        "print(\"This is a vector that is an output of a one-hot function on a softmax vector\")\n",
        "print(ohotv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vMRyLoOvuko"
      },
      "source": [
        "Version 1 provides a detailed, step-by-step breakdown of the softmax function. It shows how each input value is exponentiated, how the sum of these values is calculated, and how each is then normalized to produce a probability. This version is ideal for beginners, as it prints each intermediate step and helps visualize how raw scores are transformed into a probability distribution.\n",
        "\n",
        "Version 2 performs the same softmax computation as Version 1 but in a more compact form. It skips the intermediate outputs and simply prints the final normalized vector. This version is useful for users who already understand the softmax process and want a quick, readable implementation without the overhead of explanatory steps.\n",
        "\n",
        "Version 3 defines a reusable softmax function using NumPy and adds a one-hot encoding step. It prints the normalized vector, confirms that the values sum to 1, and then transforms the result into a one-hot vector by setting the position of the highest value to 1 and all others to 0. This version is best suited for real-world applications, such as classification tasks, where softmax output needs to be translated into a definitive decision."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKLKMe2fB_7c"
      },
      "source": [
        "# PE02"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "x_jQwmb-7tx9"
      },
      "outputs": [],
      "source": [
        "# Check if softmax list is valid. If values are between 0 and 1 and the sum of all values is equal to 1 Â± 0.01.\n",
        "def is_softmax_valid(output):\n",
        "  value = 0\n",
        "  valid = True\n",
        "\n",
        "  for f in output:\n",
        "    value += f\n",
        "\n",
        "    if f >= 0 and f <= 1:\n",
        "      continue\n",
        "    else:\n",
        "      valid = False\n",
        "\n",
        "  if value >= 0.99 and value <= 1.01 and valid == True:\n",
        "    return value, True\n",
        "  else:\n",
        "    return value, False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPRPj5eU_FYN"
      },
      "outputs": [],
      "source": [
        "# Save normalized softmax to a python float rounded to 3 decimal places\n",
        "norm_softmax = [round(float(i), 3) for i in softmax(y)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzsCClPE9cQL"
      },
      "outputs": [],
      "source": [
        "# Run the validation function, saving the result in sum and valid\n",
        "sum, valid = is_softmax_valid(norm_softmax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsJPg49k-gCe",
        "outputId": "589e7229-f26b-4394-b788-e41cff7a0502"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Normalized softmax: [0.111, 0.136, 0.273, 0.111, 0.166, 0.203]\n",
            "Sum of softmax: 1.0\n",
            "Softmax is valid: True\n"
          ]
        }
      ],
      "source": [
        "# Ouptput results\n",
        "print(f\"Normalized softmax: {norm_softmax}\")\n",
        "print(f\"Sum of softmax: {sum}\")\n",
        "print(f\"Softmax is valid: {valid}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
